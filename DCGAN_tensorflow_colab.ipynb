{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN-tensorflow-colab",
      "provenance": [],
      "collapsed_sections": [
        "ZfL7NeCofR_r"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1htd_-sguYul",
        "colab_type": "text"
      },
      "source": [
        "# DCGAN Tensorflow Colab\n",
        "\n",
        "128x128 px samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyJWCsf2t6qH",
        "colab_type": "text"
      },
      "source": [
        "This notebook is used to train and generate samples in Google Colab using code from:\n",
        "\n",
        "https://github.com/carpedm20/DCGAN-tensorflow/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmtd_DvDErgZ",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3S5q576kbgz",
        "colab_type": "text"
      },
      "source": [
        "Check if GPU is enabled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdZxqX5qkMn2",
        "colab_type": "code",
        "outputId": "9fc5e711-1b5c-4906-e7e1-f304bf1efda8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoI6Ic8HmNZ2",
        "colab_type": "text"
      },
      "source": [
        "# Install repo and import images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt5ZGDoBZwCS",
        "colab_type": "text"
      },
      "source": [
        "Connect google drive\n",
        "\n",
        "- use it at your own risk! \n",
        "- whole drive will be connected to the runtime in collab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNZoVxGaqgio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb-bw7rxZ_Ry",
        "colab_type": "text"
      },
      "source": [
        "Go to your folder in the drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE0JYtbNaDj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/drive/My Drive/Art/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38qyMuE3XtP9",
        "colab_type": "text"
      },
      "source": [
        "Use modification of the repo made by carpedm20, with fixed depracted code to run in collab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ49GKGLmK_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/hoxgen/DCGAN-Art-Tensorflow.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7_8N0XzmLF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd DCGAN-Art-Tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob5XE7hZwuwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install the necessary libraries\n",
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JnlmpLxoKsD",
        "colab_type": "text"
      },
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auwW5mgYboJO",
        "colab_type": "text"
      },
      "source": [
        "You can upload dataset using google drive directly.\n",
        "\n",
        "Create folder with images: /data/images_new/*.jpg\n",
        "\n",
        "Images have to be squares 128x128 px, jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfL7NeCofR_r",
        "colab_type": "text"
      },
      "source": [
        "## Uniform images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVvolST0hKDY",
        "colab_type": "text"
      },
      "source": [
        "Run this to avoid this error: *ValueError: could not broadcast input array from shape.. *\n",
        "\n",
        "It converts all images in a directory to RGB (it removes the alpha channel) and moves everything to a new folder\n",
        "\n",
        "Based on notebook by Sinanatra:\n",
        "\n",
        "https://colab.research.google.com/drive/18RglimpA1JH7bRbTXtxx9fAbDl60sFVQ#scrollTo=YLBwMdxMW3PR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD4-6NF6-FT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir ./data/images_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IPgA7UBZf4J",
        "colab_type": "code",
        "outputId": "f46b98ed-7719-4ece-946f-e82ad6e55e68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "os.listdir('./data/images')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__MACOSX', 'emojiFaces', '1tF1V1NKtplSNg8UQhKHlHOCvM149Du1j.zip']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbZk_1JIY_mr",
        "colab_type": "code",
        "outputId": "8e24f5bb-b66b-46ab-c7a0-b41a466d02f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from PIL import Image\n",
        "import os, sys\n",
        "\n",
        "path ='./data/images/emojiFaces/'\n",
        "out=\"./data/images_new/\"\n",
        "\n",
        "dirs = os.listdir( path )\n",
        "\n",
        "n=0\n",
        "for item in dirs:\n",
        "    try:\n",
        "        if os.path.isfile(path+item):\n",
        "            im = Image.open(path+item)\n",
        "            longer_side = max(im.size)\n",
        "\n",
        "            horizontal_padding = (longer_side - im.size[0]) / 2\n",
        "            vertical_padding = (longer_side - im.size[1]) / 2\n",
        "            f, e = os.path.splitext(path+item)\n",
        "            imResize = im.crop(\n",
        "            (\n",
        "                -horizontal_padding,\n",
        "                -vertical_padding,\n",
        "                im.size[0] + horizontal_padding,\n",
        "                im.size[1] + vertical_padding\n",
        "            )\n",
        "            )\n",
        "            RGB = imResize.convert('RGB')\n",
        "            little = RGB.resize((128,128), Image.ANTIALIAS) # was 108\n",
        "\n",
        "            little.save(out +  str(n) +'resize.jpg', 'JPEG', quality=90)\n",
        "            n+=1\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cannot identify image file './data/images/emojiFaces/.DS_Store'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HSVWO--Wuw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.listdir('./data/images_new')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-NvQtkJxCeB",
        "colab_type": "text"
      },
      "source": [
        "# Train\n",
        "and generate test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKXJvmiqPfEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd \"/content/drive/My Drive/Art/DCGAN-Art-Tensorflow/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDzw6Rvyurjd",
        "colab_type": "text"
      },
      "source": [
        "Run training with %%capture to avoid memory overload in chrome browser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPPAxSqXO5iV",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!python main.py  --batch_size 64 --generate_test_images 16 --dataset images_new -c_dim 1 --epoch 300  --input_fname_pattern \"*.jpg\" --input_height 128 --output_height 128  --option 2 --train  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8d3Bt2lqwTL",
        "colab_type": "text"
      },
      "source": [
        "#Generete samples from checkpoint\n",
        "\n",
        "Checkpoints have to be in /checkpoint/images_new_64_128_128 folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oidZz30PxSoS",
        "colab_type": "text"
      },
      "source": [
        "Generate samples - Option 0 - One test image sheet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztLN0j7qUwUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python main.py  --batch_size 64 --generate_test_images 16  --dataset images_new -c_dim 3  --input_height 128 --output_height 128  --option 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAozFl3zbeOd",
        "colab_type": "text"
      },
      "source": [
        "Generate samples - Option 1 - Multiple samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS8tSEVKTIsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python main.py  --batch_size 64 --generate_test_images 16  --dataset images_new -c_dim 3  --input_height 128 --output_height 128  --visualize True --option 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJzwJCmDblE6",
        "colab_type": "text"
      },
      "source": [
        "Generate samples - Option 2 - gif interpolation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cklCvvu_bpKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python main.py  --batch_size 64 --generate_test_images 16  --dataset images_new -c_dim 3  --input_height 128 --output_height 128  --visualize True --option 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GlN6dTHcUYO",
        "colab_type": "text"
      },
      "source": [
        "Generate samples - Option 3 - gif with \"growing\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAXhS4sccV81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python main.py  --batch_size 64 --generate_test_images 16  --dataset images_new -c_dim 3  --input_height 128 --output_height 128  --visualize True --option 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RXPnhb3cYCx",
        "colab_type": "text"
      },
      "source": [
        "Generate samples - Option 4 - gif \"growing merged\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZtS7CP3cbI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python main.py  --batch_size 64 --generate_test_images 16  --dataset images_new -c_dim 3  --input_height 128 --output_height 128  --visualize True --option 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhQBTSyCcG-1",
        "colab_type": "text"
      },
      "source": [
        "Remove samples if needed - use with caution to not loose stuff!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asotRId_2tRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rm -R samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu0fuzQ4Sh9d",
        "colab_type": "text"
      },
      "source": [
        "# Save files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n481JJOqArJ5"
      },
      "source": [
        "files are saved to /samples in your Google Drive"
      ]
    }
  ]
}